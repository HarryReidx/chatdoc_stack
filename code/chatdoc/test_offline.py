#!/usr/bin/env python3
"""
ç¦»çº¿æœ¬åœ°æœåŠ¡æµ‹è¯•è„šæœ¬ - ä½¿ç”¨å›½å†…é•œåƒå’Œç¼“å­˜
Author: AI Assistant
Date: 2025-07-28
"""
import sys
import os
import time

def setup_huggingface_mirror():
    """è®¾ç½®HuggingFaceé•œåƒ"""
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    print("âœ… å·²è®¾ç½®HuggingFaceé•œåƒ: https://hf-mirror.com")

def test_imports():
    """æµ‹è¯•åŸºæœ¬å¯¼å…¥"""
    print("=== æµ‹è¯•åŸºæœ¬å¯¼å…¥ ===")
    
    try:
        import torch
        print("âœ… torch å¯¼å…¥æˆåŠŸ")
        print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    except ImportError as e:
        print(f"âŒ torch å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import transformers
        print("âœ… transformers å¯¼å…¥æˆåŠŸ")
        print(f"   ç‰ˆæœ¬: {transformers.__version__}")
    except ImportError as e:
        print(f"âŒ transformers å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import sentence_transformers
        print("âœ… sentence_transformers å¯¼å…¥æˆåŠŸ")
        print(f"   ç‰ˆæœ¬: {sentence_transformers.__version__}")
    except ImportError as e:
        print(f"âŒ sentence_transformers å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•megaparseå¯¼å…¥ï¼ˆå¯èƒ½å¤±è´¥ï¼Œä½†ä¸å½±å“å…¶ä»–åŠŸèƒ½ï¼‰
    try:
        import megaparse
        print("âœ… megaparse å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âš ï¸ megaparse å¯¼å…¥å¤±è´¥: {e}")
        print("   è¿™å¯èƒ½æ˜¯ç‰ˆæœ¬å†²çªï¼Œä½†ä¸å½±å“å…¶ä»–åŠŸèƒ½æµ‹è¯•")
    
    return True


def test_embedding_simple():
    """æµ‹è¯•ç®€å•çš„åµŒå…¥åŠŸèƒ½"""
    print("\n=== æµ‹è¯•åµŒå…¥åŠŸèƒ½ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰===")
    
    try:
        from transformers import AutoTokenizer, AutoModel
        import torch
        
        # ä½¿ç”¨ä¸€ä¸ªå°çš„ä¸­æ–‡æ¨¡å‹
        model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
        print("é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        try:
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModel.from_pretrained(model_name)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # æµ‹è¯•ç¼–ç 
            test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
            inputs = tokenizer(test_text, return_tensors="pt", padding=True, truncation=True)
            
            with torch.no_grad():
                outputs = model(**inputs)
                # ä½¿ç”¨mean pooling
                embeddings = outputs.last_hidden_state.mean(dim=1)
            
            print(f"âœ… æ–‡æœ¬åµŒå…¥æˆåŠŸï¼Œå‘é‡ç»´åº¦: {embeddings.shape[1]}")
            return True
            
        except Exception as e:
            if "connection" in str(e).lower() or "timeout" in str(e).lower():
                print(f"âš ï¸ ç½‘ç»œè¿æ¥é—®é¢˜: {e}")
                print("   å»ºè®®ï¼š")
                print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                print("   2. ä½¿ç”¨VPNæˆ–ä»£ç†")
                print("   3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°")
                return False
            else:
                raise e
        
    except Exception as e:
        print(f"âŒ åµŒå…¥åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_local_embedding_class():
    """æµ‹è¯•æœ¬åœ°åµŒå…¥ç±»ï¼ˆä¸ä¾èµ–é…ç½®ï¼‰"""
    print("\n=== æµ‹è¯•æœ¬åœ°åµŒå…¥ç±» ===")
    
    try:
        from sentence_transformers import SentenceTransformer
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„åµŒå…¥æœåŠ¡ç±»
        class SimpleEmbeddingService:
            def __init__(self, model_name="paraphrase-multilingual-MiniLM-L12-v2"):
                print(f"æ­£åœ¨åˆå§‹åŒ–åµŒå…¥æœåŠ¡ï¼Œæ¨¡å‹: {model_name}")
                self.model = SentenceTransformer(model_name)
                print("âœ… åµŒå…¥æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            def encode_single(self, text):
                return self.model.encode(text)
            
            def encode_batch(self, texts):
                return self.model.encode(texts)
        
        # æµ‹è¯•æœåŠ¡
        service = SimpleEmbeddingService()
        
        # æµ‹è¯•å•æ–‡æœ¬
        embedding = service.encode_single("æµ‹è¯•æ–‡æœ¬")
        print(f"âœ… å•æ–‡æœ¬åµŒå…¥æˆåŠŸï¼Œç»´åº¦: {len(embedding)}")
        
        # æµ‹è¯•æ‰¹é‡
        embeddings = service.encode_batch(["æ–‡æœ¬1", "æ–‡æœ¬2"])
        print(f"âœ… æ‰¹é‡åµŒå…¥æˆåŠŸï¼Œæ•°é‡: {len(embeddings)}")
        
        return True
        
    except Exception as e:
        if "connection" in str(e).lower() or "timeout" in str(e).lower():
            print(f"âš ï¸ ç½‘ç»œè¿æ¥é—®é¢˜: {e}")
            return False
        else:
            print(f"âŒ æœ¬åœ°åµŒå…¥ç±»æµ‹è¯•å¤±è´¥: {e}")
            return False


def test_local_rerank_class():
    """æµ‹è¯•æœ¬åœ°é‡æ’åºç±»ï¼ˆä¸ä¾èµ–é…ç½®ï¼‰"""
    print("\n=== æµ‹è¯•æœ¬åœ°é‡æ’åºç±» ===")
    
    try:
        from sentence_transformers import CrossEncoder
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„é‡æ’åºæœåŠ¡ç±»
        class SimpleRerankService:
            def __init__(self, model_name="cross-encoder/ms-marco-MiniLM-L-12-v2"):
                print(f"æ­£åœ¨åˆå§‹åŒ–é‡æ’åºæœåŠ¡ï¼Œæ¨¡å‹: {model_name}")
                self.model = CrossEncoder(model_name)
                print("âœ… é‡æ’åºæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            def rerank(self, query, documents):
                pairs = [[query, doc] for doc in documents]
                scores = self.model.predict(pairs)
                return scores.tolist() if hasattr(scores, 'tolist') else list(scores)
        
        # æµ‹è¯•æœåŠ¡
        service = SimpleRerankService()
        
        # æµ‹è¯•é‡æ’åº
        query = "äººå·¥æ™ºèƒ½"
        documents = ["AIæ˜¯æœªæ¥", "ä»Šå¤©å¤©æ°”å¥½", "æœºå™¨å­¦ä¹ å¾ˆé‡è¦"]
        scores = service.rerank(query, documents)
        
        print(f"âœ… é‡æ’åºæˆåŠŸï¼Œåˆ†æ•°: {scores}")
        
        # æ˜¾ç¤ºæ’åºç»“æœ
        sorted_results = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)
        print("   æ’åºç»“æœ:")
        for i, (doc, score) in enumerate(sorted_results):
            print(f"     {i+1}. {doc} (åˆ†æ•°: {score:.4f})")
        
        return True
        
    except Exception as e:
        if "connection" in str(e).lower() or "timeout" in str(e).lower():
            print(f"âš ï¸ ç½‘ç»œè¿æ¥é—®é¢˜: {e}")
            return False
        else:
            print(f"âŒ æœ¬åœ°é‡æ’åºç±»æµ‹è¯•å¤±è´¥: {e}")
            return False


def test_alternative_pdf_parser():
    """æµ‹è¯•æ›¿ä»£çš„PDFè§£ææ–¹æ¡ˆ"""
    print("\n=== æµ‹è¯•æ›¿ä»£PDFè§£ææ–¹æ¡ˆ ===")
    
    try:
        # å¦‚æœmegaparseæœ‰é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å…¶ä»–æ–¹æ¡ˆ
        import PyPDF2
        print("âœ… PyPDF2 å¯ç”¨ä½œå¤‡é€‰PDFè§£æå™¨")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„PDFè§£æç±»
        class SimplePDFParser:
            def parse_pdf(self, pdf_bytes):
                import io
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_bytes))
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text()
                return text
        
        parser = SimplePDFParser()
        print("âœ… ç®€å•PDFè§£æå™¨åˆ›å»ºæˆåŠŸ")
        
        return True
        
    except ImportError:
        print("âš ï¸ PyPDF2 æœªå®‰è£…ï¼Œå¯ä»¥ä½œä¸ºmegaparseçš„å¤‡é€‰æ–¹æ¡ˆ")
        print("   å®‰è£…å‘½ä»¤: pip install PyPDF2")
        return True  # ä¸ç®—å¤±è´¥ï¼Œåªæ˜¯æç¤º


def main():
    """ä¸»å‡½æ•°"""
    print("=== ç¦»çº¿æœ¬åœ°æœåŠ¡æµ‹è¯• ===")
    print("æ­¤æµ‹è¯•ä½¿ç”¨å›½å†…é•œåƒï¼Œé€‚åˆç½‘ç»œå—é™ç¯å¢ƒ\n")
    
    # è®¾ç½®é•œåƒ
    setup_huggingface_mirror()
    
    tests = [
        ("åŸºæœ¬å¯¼å…¥", test_imports),
        ("åµŒå…¥åŠŸèƒ½ï¼ˆç®€å•ç‰ˆï¼‰", test_embedding_simple),
        ("æœ¬åœ°åµŒå…¥ç±»", test_local_embedding_class),
        ("æœ¬åœ°é‡æ’åºç±»", test_local_rerank_class),
        ("æ›¿ä»£PDFè§£æ", test_alternative_pdf_parser)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*60}")
        print(f"å¼€å§‹æµ‹è¯•: {test_name}")
        print('='*60)
        
        try:
            if test_func():
                passed += 1
                print(f"\nâœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"\nâŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"\nâŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total}")
    print('='*60)
    
    if passed >= 3:  # è‡³å°‘3ä¸ªæµ‹è¯•é€šè¿‡å°±ç®—æˆåŠŸ
        print("ğŸ‰ æ ¸å¿ƒåŠŸèƒ½åŸºæœ¬å¯ç”¨ï¼")
        print("\nâœ… åŸºç¡€ç»„ä»¶å¯ä»¥å·¥ä½œ")
        print("âœ… å¯ä»¥å°è¯•é›†æˆåˆ°chatdocç³»ç»Ÿ")
        print("\nå»ºè®®:")
        print("1. å¦‚æœç½‘ç»œå…è®¸ï¼Œè®©æ¨¡å‹åœ¨åå°ä¸‹è½½")
        print("2. è€ƒè™‘ä½¿ç”¨ç¦»çº¿æ¨¡å‹æˆ–æœ¬åœ°æ¨¡å‹")
        print("3. å¦‚æœmegaparseæœ‰é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨PyPDF2ä½œä¸ºå¤‡é€‰")
        return True
    else:
        print("âŒ å¤§éƒ¨åˆ†åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. ä½¿ç”¨VPNæˆ–ä»£ç†")
        print("3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°")
        print("4. ä½¿ç”¨æ›´ç®€å•çš„æ›¿ä»£æ–¹æ¡ˆ")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
